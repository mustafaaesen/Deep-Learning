# -*- coding: utf-8 -*-
"""Deep Learning Project-2 Get a Loan? .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jOEAFl9qV1Eh1OIewFc2xG4DQjr8JAOY
"""

#Proje 2 Kredi Alabilir mi?

"""
Hedef:
--->Kişinin gelir,yaş,borç gibi özelliklerine bakarak
kredi alabilir mi(1) veya alamaz mı(0) tahmini yapmak.

Bu proje Yapay sinir ağları ile çözeceğimiz binary sınıflandırma
problemidir.

TEKNOLOJİLER
-->Pandas/Numpy -> Veri İşleme
-->Scikit_learn ->veri seti, ön işleme, değerlendirme
-->Tensorflow/Keras -> Yapay Sinir Ağı modeli
-->Matplotlib/Seaborn ->Grafik


"""

#GEREKLİ KÜTÜPHANELER

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
#veri seti ön işleme

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
#derin öğrenme için gerekli kütüphaneler

from sklearn.metrics import accuracy_score,confusion_matrix, classification_report
#Değerlendirme için

from google.colab import files

# Dosya yükleme penceresini açar
uploaded = files.upload()

"""
Elimizde müşterilerin
| Sütun Adı             | Açıklama                        |
| --------------------- | ------------------------------- |
| ID                    | Müşteri ID'si                   |
| CODE\_GENDER          | Cinsiyet                        |
| FLAG\_OWN\_CAR        | Araba sahibi mi?                |
| FLAG\_OWN\_REALTY     | Ev sahibi mi?                   |
| CNT\_CHILDREN         | Çocuk sayısı                    |
| AMT\_INCOME\_TOTAL    | Gelir                           |
| NAME\_INCOME\_TYPE    | Gelir türü (çalışan, emekli...) |
| NAME\_EDUCATION\_TYPE | Eğitim durumu                   |
| NAME\_FAMILY\_STATUS  | Medeni durumu                   |
| DAYS\_BIRTH           | Doğum günü (negatif değer)      |
| DAYS\_EMPLOYED        | Çalışma süresi                  |
| ...                   | vs.                             |


gibi verilerini tutan application.record.csv ve


| Sütun Adı       | Açıklama                                                           |
| --------------- | ------------------------------------------------------------------ |
| ID              | Müşteri ID'si                                                      |
| MONTHS\_BALANCE | Kredi geçmişi ay bilgisi                                           |
| STATUS          | Kredi durumu (0: zamanında, 1–5: gecikme, C: kapalı, X: bilgi yok) |


müşterilerin daha önce kredi kullnaıp kullanmadığıyla ilgili credit_record.csv

olmak üzere iki veri seti mevcut önce bu veri setlerini  içeri alıp önişleme s
sırasında bilrşetirmeye çalışacağız





"""

#veri setlerini dataframe e çekme

import pandas as pd

app_df = pd.read_csv("application_record.csv")
#müşteri bilgilerinin atanması

credit_df = pd.read_csv("credit_record.csv")
#daha önce kullandıysa kredi bilgileri


print("Application Veri Seti:")
#ilk  bir kaç satırı görüntüleme
display(app_df.head())

print("Credit Veri Seti:")
display(credit_df.head())

"""
credit_record içerisnde düzenlemeler yapaacığz

en riskli durumun tespiti

gecikme yoksa 1 kredi alabilir varsa 0 yüksek riksli şeklinde
etiket sütunu oluşturacağız(TARGET)

"""
# Önce kredi durumundaki eşsiz değerleri görelim
print("Eşsiz kredi durumları (STATUS):", credit_df["STATUS"].unique())

#Her müşteri için en kötü durumların bulunup etiketlenmesi




status_summary = credit_df.groupby("ID")["STATUS"].apply(lambda x: ''.join(set(x)))
#her id için en kötü durumu bulur daha sonra içlerinden en kötüsünü bulur

#gecikmeli ödemesi olup olmadığına bakan fonksiyon
def is_good_credit(statur_str):

  for risk in ['1','2','3','4','5']:

    if risk in statur_str:# riskli müşteri tespiti

      return 0

  return 1 #güvenilir müşteri


credit_status = status_summary.apply(is_good_credit).reset_index()
#tüm müşterilere etiket atılması

credit_status.columns = ["ID","TARGET"]


credit_status.head()

#Her müşterinin kredi durumu target sütunu oluşturulup sonuçlar yazıldı

#Setlerin Birleştirilmesi

merged_df = pd.merge(app_df, credit_status, on = "ID")
# id lere göre veri setlerinin birleştirilmesi

merged_df.head()

#Kontrol: Hedef Değerlerin dağılımı

#burada veri setinden bozukluk gelip gelmediğini kontrol edeceğiz
#sağlıklı çalışma için önemlidir

merged_df["TARGET"].value_counts()
# 0 = Riskli müşteri, 1 = Güvenilir müşteri

#ÖNİŞLEME ve VERİ SETİ TEMİZLİĞİ

columns_to_drop = [


    'ID',
    'FLAG_MOBIL',
    'FLAG_WORK_PHONE',
    'FLAG_PHONE',
    'FLAG_EMAIL',
    'OCCUPATION-TYPE'
]

merged_df.drop(columns = [col for col in columns_to_drop if col in merged_df.columns],axis=1,inplace=True)

# Sütunları düşürme

merged_df.info()

#Kategorik Sütunları Sayısala Çevirme(Encoding)

categorical_cols = merged_df.select_dtypes(include='object').columns.tolist()
#Kategorik verilerin seçilmesi

merged_df_encoded = pd.get_dummies(merged_df,columns=categorical_cols, drop_first=True)
#encoding uygulama

print("Yeni sütun sayısı:",merged_df_encoded.shape[1])
merged_df_encoded.head()

#SAyısal verilerin ölçeklenmesi

from sklearn.preprocessing import StandardScaler

X= merged_df_encoded.drop("TARGET",axis=1)
y=merged_df_encoded["TARGET"]
#hedef değişkenlerin atanması

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=42)
#eğtitim ve test verisi ayarlanması

scaler=StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
#sayısal değerlerin ölçeklenmesi

#Model Tanımlama

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense


model = Sequential()
#katmanlı modeller oluşturma

model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))
#giriş gizli katmanı

model.add(Dense(32, activation='relu'))
#ikinci gizli katman

model.add(Dense(16,activation='relu'))
#üçüncü gizli katman

model.add(Dense(1,activation='sigmoid'))
#çıktı katmanı  binary classifitaion-->sigmoid

#Modeli Derleme

model.compile(

    optimizer='adam',    #ağırlıkları her seferinde güncellyen algoritma
    loss='binary_crossentropy', # 0/1 sınıflandırma için
    metrics=['accuracy'] # doğruluk oranını takip et
)

from sklearn.utils import class_weight
import numpy as np

# Sınıf ağırlıklarını otomatik hesapla
weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)

# Sözlük haline getir
class_weights = {0: weights[0], 1: weights[1]}

print("Sınıf ağırlıkları:", class_weights)

#Model Eğitimi

history = model.fit(
    X_train_scaled,
    y_train,
    epochs=20,
    batch_size=32,
    validation_split=0.1,
    verbose=1,
    class_weight=class_weights   # 🟢  burası eklendi
)

#Doğruluk Görselleştirme

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'],label='Eğitim')
plt.plot(history.history['val_accuracy'],label='Doğrulama')
plt.title('Model Doğruluğu')
plt.ylabel('Doğruluk')
plt.xlabel('Epoch')
plt.legend()
plt.grid()
plt.show()

#Modeli Test Etme

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

y_pred_prob=model.predict(X_test_scaled)
y_pred= (y_pred_prob>0.5).astype(int)
#tahminler 0.5 üstü ise 1 kabul etmek için

print("Test Doğruluğu:",accuracy_score(y_test,y_pred))
print("Confusion Matrix:\n",confusion_matrix(y_test,y_pred))
print("Classification Report:\n",classification_report(y_test,y_pred))

"""
Modelin doğruluk oranı yüksek %88 ancak veri
Recall çok düşük → Yani gerçek riskli müşterileri yakalayamıyor

F1-score = 0.09 → Bu sınıf için model başarısız

bunun için class weight ağırlığını kullnıp tekrar model eğitimi yapcağız

Bu sayede model az sayıda bulunan riskli müşterilere özen gösterecek

"""

#class weight ekledikten sonra accuracy düştü ancak daha güvenilir bir model elde ettik
#çünkü model artık her şeye 1 demiyor riskli müşterileri daha az kaçırıyor