# -*- coding: utf-8 -*-
"""Deep Learning Intro&Project-1 MNIST  .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MMW7y3NVzbfMxQ0wj35FIqb87j_SlZ-d
"""

#1) YAPAY SİNİR AĞI(ANN)

"""
--->İnsan beynindeki nöronlardan ilham alan matematiksel
yapılardır.

--->Genellikle veri girişi->işleme->tahmin/çıktı üretme
döngüsünde çalışır.

TEMEL YAPI
-Girdi Katmanı(Input Layer)
-Gizli Katman(lar)(Hidden Layer)
-Çıktı Katmanı(Output Layer)

--->Her katmanda nöron denilen birimler vardır.

--->Nöronlar girişleri alır,bunları ağırlıklarla çarpar, bir aktivasyon
fonksiyonudan geçirip diğer katmana aktarır.

"""

#2) KATMANLAR

"""
DENSE (Tam Bağlantılı Katman)
--->Her nöron bir önceki katmandaki tüm nöronlara bağlıdır.

     Örnek Python

     from tensorflow.keras.layers import Dense
     Dense(units=64,activation='relu')

     units-->Nöron sayısıdır.
     activation-->Aktivaston Fonksiyonu

Activation Foknsiyonu

--->Nöro çıkışında kullanılır.
--->Doğrusal olmayan karar almayı sağlar

    En Yaygınları

    ReLU --> Negatifleri sıfırlar,pozitiflerş olduğu gibi
    geçer.Gizli katmanlarda sıkça kullanılır.

    Sigmoid -->(0,1) arası çıkış verir.Binary sınıflandırmada iyidir.

    Softmax -->Çok sınıflı problemler için .Çıkışları olasılığı dönüştürür.



"""

#3) TensorFlow & Keras

"""
TensorFlow

   --->Google tarafından geliştirilen makine öğrenmesi framework'üdür.

Keras

   --->TensorFlow içinde çalışan daha kolay ve hızlı kurulumunu sağlayan
   bir API'dır.


Örnek Python

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model=Sequential([

   Dense(128,activation='relu',input_shape(784,))
   Dense(64, activation='relu')
   Dense(10,activation='softmax')

])

Sequential--->Katmanları sırayla tanımlar.

input_shape--->Giriş verisinin boyutu(28x28=784)

softmax ---> Son katmanda 10 sınıf varsa kullanılır.
(MNIST rakamları 0-9)

"""

#4) Model Eğitimi: Epoch & Batch Size

"""
Epoch:

  --->Tüm eğitim verisinin bir kez modelden geçmesidir.
  --->Genellikle modelin öğrenmesi için 5-5*0 epoch arası kullanılır.


Batch Size:

  --->Modelin aynı anda işleyeceği örnek sayısıdır.
  --->Örneğin Batch Size=32 her seferinde 32 örnekle güncelleme yapılır.

"""

#5) Model Derleme ve Eğitim


"""

model.compile(optimizer='adam', lodd='categorical_crossentropy', metrics=['accuracy])

model.fit(x_train, y_train, epochs=10, batch_size=32)


optimizer='adam':

    --->Modelin ağırlıklarını nasıl güncelleyceğini belirler.
    adam-->En yaygın kullanılan optimize edici algoritmalardan biridir.
    --->adaptif öğrenme oranı kullanılır(hem hızlı, hem kararlı)


loss='categorical_crossentropy'
Kayıp Fonksiyonu(loss):

    --->Modelin yaptığı tahminlerle gerçek etiket arasındaki farkı hesaplar
    --->Çok sınıflı sınıflandırma problemlerinde kullanılır.

metrics=['accuracy']:

    --->Model performansını değerlendirmek için hangi metriğin kullanılacağını
    belirtilmesi.

    --->accuracy--> Doğru tahmin edilen örneklerin oranı.
    --->Sınıflandırma probelemlerinde kullanılır.

"""

#SÜREÇ ÖZET

"""
1) VERİ HAZIRLAMA --->Normalizasyon,etiket dönüşümü

2) MODEL KURMA    --->Sequential ile katmanları sırayla oluşturma

3) DERLEME        --->Hangi optimizer ve kayıp fonksiyonlarının uygulancağı.

4) EĞİTİM(fit)    --->Veriyi modele verip öğrenmesini sağlama.

5) DEĞERLENDİRME  --->Test verisiyle başarı ölçütü.

6)TAHMİN(predict) --->Yeni verilerle çıktı üretme.

"""

#ÖRNEK PROJE
#El Yazısı Rakamları Tanıyan Yapay Sinir Ağı (MNIST)

"""
Hedef
--->28x28 boyutundaki el yazısı rakam görsellerinden (0–9 arası) hangi
rakam olduğunu tahmin eden bir model geliştirmek.

Araçlar

TensorFlow / Keras

MNIST veri seti (Keras’ın içinden hazır geliyor)

Yapay Sinir Ağı (ANN) — sadece Dense katmanlarla

"""

#Gerekli Kütüphaneler

import numpy as np
#sayısal işlemler için

import matplotlib.pyplot as plt
#veri görselleştrime için

import tensorflow as tf
# derin öğrenme kütüphanesi,keras ile model oluşturulacak

from tensorflow.keras.datasets import mnist
#MNIST veri setini yüklemek için çağırım

from tensorflow.keras.models import Sequential
#model oluşturmak için Sequential sınıfı tanımı

from tensorflow.keras.layers import Dense,Flatten
#yapay sinir ağı katmanları için dense,flatten gibi katmanların eklenmesi

from tensorflow.keras.utils import to_categorical
#etiketleri one-hot vektöze edebilmek için

#MNIST VERİ SETİ YÜKLEME

(x_train, y_train),(x_test, y_test) = mnist.load_data()
#MNIST veri seti eğitim ve test verisi olarak ayrılmış şeklide gelmektedir.

print("Eğitim veri şekli (görseller):" ,x_train.shape)
#x_train el yazısı rakam görselleri (28x28 boyutunda)

print("Eğitim etiketleri şekli:",y_train.shape)
#y_train bu resimlere karşılık gelen rakam etiketleri(0-9 arası)

#VERİYİ GÖRSELLEŞTİRME
#ilk resmi ve etiketini görüntüleme deneme amaçlı
plt.imshow(x_train[0], cmap="gray") #görüntüüyü gri tonlarda gösterme
plt.title(f"Etiket: {y_train[0]}")
plt.axis("off")
plt.show()

#VERİ ÖNİŞLEME

#görsellerin pixel değerleri 0-255 aralığında bunu 0-1 aralığına normalize
#etmeliyiz

x_train = x_train/255.0
x_test = x_test/255.0


#Etiketleri one-hot kodlamaya çevirme

y_train=to_categorical(y_train,10)
y_test = to_categorical(y_test,10)

#MODEL TANIMLAMA

model=Sequential()# modeli oluşturmak için sequential sınıfını başlatma

model.add(Flatten(input_shape=(28,28)))#ilk katmanı düzleştirme 28x28=784

model.add(Dense(128,activation='relu'))#ikinci katmanı 128 nöronlu gizli katman
#olarak ayarlama ReLU aktivasyonuyla

model.add(Dense(64,activation='relu'))#üçüncü katmanı 64 nöronlu ikinci gizli
#katman olarak ayarlama ReLU aktivasyonuyla

model.add(Dense(10,activation='softmax'))#çıkış katmanı 10 sınıf(0-9 rakamları)
#softmax ile olasılığa dönüştürüldü

#MODELİ DERLEME

model.compile(
    optimizer='adam',  #ağırlıkalrı optimize eden adam algoritması
    loss='categorical_crossentropy',  # çok sınıflı sınıflandırma için uygun kayıp
    #fonksiyonu
    metrics=['accuracy']#Doğruluk oranını kontrol için accuracy
)

#MODEL EĞİTİMİ

history= model.fit(
    x_train, y_train,  #eğitim verileri
    epochs=10,   # tüm veri seti 10 kez modele  gösterilecek
    batch_size=32, #her eğitim adımında 32 örnek kullanılacak
    validation_split=0.1,#eğitim verisinin %10 u doğrulama için ayırılacak
    verbose=1 #eğitim sırasında çıktıların gösterilmesini sağlar
)

#TEST VERİSİ ile DEĞERLENDİRME

test_loss, test_accuracy= model.evaluate(x_test, y_test)
#eğitimden sonra modeli test verileri değerlendirme

print(f"\nTest Kayıp (Loss): {test_loss: .4f}")
print(f"Test Doğruluk (Accuracy): %{test_accuracy * 100:.2f} ")

#TAHMİNLERİN GÖRSELLEŞTİRİLMESİ

predictions=model.predict(x_test)
#test setindeki tahminlerin alınması

#ilk 5 resmi tahminleriyle birlikte yazma

for i in range(5):

  plt.imshow(x_test[i], cmap="gray")
  plt.title(f"Gerçek: {np.argmax(y_test[i])} | Tahmin: {np.argmax(predictions[i])}")
  plt.axis("off")
  plt.show()

#MODEL KAYDETME

model.save("mnist_ann_model.h5")